"""IndexTTS æ ¸å¿ƒæ¨ç†å¼•æ“"""
import asyncio
import inspect
import logging
import os
import sys
import time
import uuid
from collections import OrderedDict
from pathlib import Path
from typing import Optional, Dict, Any
import torch
import numpy as np
import soundfile as sf

from app.core.config import settings

logger = logging.getLogger(__name__)

# é˜Ÿåˆ—é…ç½®
MAX_QUEUE_SIZE = 50


class QueueItem:
    """é˜Ÿåˆ—é¡¹"""
    def __init__(self, request_id: str):
        self.request_id = request_id
        self.created_at = time.time()
        self.status = "pending"  # pending, processing, completed, error


class TTSQueue:
    """TTS è¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨"""

    def __init__(self, max_size: int = MAX_QUEUE_SIZE):
        self.max_size = max_size
        self._queue: OrderedDict[str, QueueItem] = OrderedDict()
        self._lock = asyncio.Lock()
        self._current_processing: Optional[str] = None

    async def add(self, request_id: str) -> tuple[bool, int]:
        """æ·»åŠ è¯·æ±‚åˆ°é˜Ÿåˆ—ï¼Œè¿”å› (æ˜¯å¦æˆåŠŸ, ä½ç½®)"""
        async with self._lock:
            if len(self._queue) >= self.max_size:
                return False, -1

            item = QueueItem(request_id)
            self._queue[request_id] = item
            position = list(self._queue.keys()).index(request_id) + 1
            return True, position

    async def remove(self, request_id: str):
        """ä»é˜Ÿåˆ—ç§»é™¤è¯·æ±‚"""
        async with self._lock:
            if request_id in self._queue:
                del self._queue[request_id]
            if self._current_processing == request_id:
                self._current_processing = None

    async def set_processing(self, request_id: str):
        """è®¾ç½®æ­£åœ¨å¤„ç†çš„è¯·æ±‚"""
        async with self._lock:
            self._current_processing = request_id
            if request_id in self._queue:
                self._queue[request_id].status = "processing"

    async def get_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        async with self._lock:
            return {
                "queue_length": len(self._queue),
                "max_queue_size": self.max_size,
                "is_processing": self._current_processing is not None,
                "current_processing": self._current_processing,
                "can_submit": len(self._queue) < self.max_size,
            }

    async def get_position(self, request_id: str) -> int:
        """è·å–è¯·æ±‚åœ¨é˜Ÿåˆ—ä¸­çš„ä½ç½® (1-based), å¦‚æœä¸åœ¨é˜Ÿåˆ—ä¸­è¿”å› -1"""
        async with self._lock:
            if request_id not in self._queue:
                return -1
            return list(self._queue.keys()).index(request_id) + 1


# å…¨å±€é˜Ÿåˆ—å®ä¾‹
tts_queue = TTSQueue(MAX_QUEUE_SIZE)


class TTSModelEngine:
    """TTS æ¨¡å‹æ¨ç†å¼•æ“ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""

    def __init__(self):
        self.model = None
        self.device = settings.device
        self.inference_lock = asyncio.Lock()  # æ˜¾å­˜ä¿æŠ¤é”
        self.is_loaded = False

    def load_model(self):
        """åŠ è½½æ¨¡å‹åˆ° GPU"""
        if self.is_loaded:
            logger.info("æ¨¡å‹å·²åŠ è½½ï¼Œè·³è¿‡é‡å¤åŠ è½½")
            return

        requested_device = self.device
        if requested_device == "auto":
            if torch.cuda.is_available():
                resolved_device = "cuda"
            elif hasattr(torch, "xpu") and torch.xpu.is_available():
                resolved_device = "xpu"
            elif hasattr(torch, "mps") and torch.backends.mps.is_available():
                resolved_device = "mps"
            else:
                resolved_device = "cpu"
        else:
            resolved_device = requested_device
            if requested_device.startswith("cuda") and not torch.cuda.is_available():
                logger.warning("CUDA ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
                resolved_device = "cpu"
            if requested_device == "mps" and not (hasattr(torch, "mps") and torch.backends.mps.is_available()):
                logger.warning("MPS ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
                resolved_device = "cpu"
            if requested_device == "xpu" and not (hasattr(torch, "xpu") and torch.xpu.is_available()):
                logger.warning("XPU ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
                resolved_device = "cpu"

        if resolved_device != self.device:
            logger.info(f"è®¾å¤‡è°ƒæ•´: {self.device} -> {resolved_device}")
        self.device = resolved_device

        logger.info(f"å¼€å§‹åŠ è½½ IndexTTS æ¨¡å‹åˆ° {self.device}...")

        try:
            # å°è¯•å¯¼å…¥ IndexTTS
            try:
                repo_candidates = []
                env_repo = os.environ.get("INDEX_TTS_REPO_DIR")
                if env_repo:
                    repo_candidates.append(Path(env_repo))
                repo_candidates.append(settings.index_tts_repo_dir)
                try:
                    repo_candidates.append(Path(__file__).resolve().parents[2] / "index-tts")
                except Exception:
                    pass
                repo_candidates.append(Path.cwd() / "index-tts")
                repo_candidates.append(Path("/root/index-tts"))

                repo_root = None
                for candidate in repo_candidates:
                    try:
                        if (candidate / "indextts").is_dir():
                            repo_root = candidate
                            break
                    except Exception:
                        continue

                if repo_root:
                    repo_root_str = str(repo_root)
                    if repo_root_str not in sys.path:
                        sys.path.insert(0, repo_root_str)
                    logger.info(f"ä½¿ç”¨ IndexTTS ä»“åº“è·¯å¾„: {repo_root}")
                else:
                    logger.warning("æœªæ‰¾åˆ° IndexTTS ä»“åº“ï¼Œå°†å°è¯•ä½¿ç”¨å·²å®‰è£…çš„ indextts åŒ…")

                # å¦‚æœéœ€è¦ä½¿ç”¨ HF é•œåƒ
                if "HF_ENDPOINT" not in os.environ:
                    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

                from indextts.infer_v2 import IndexTTS2

                try:
                    logger.info(f"IndexTTS2 å¯¼å…¥è·¯å¾„: {inspect.getfile(IndexTTS2)}")
                except Exception:
                    pass

                # æ„å»ºé…ç½®æ–‡ä»¶è·¯å¾„
                cfg_path = settings.weights_dir / "config.yaml"

                # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not cfg_path.exists():
                    logger.warning(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {cfg_path}")
                    raise FileNotFoundError(f"æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {cfg_path}")

                # åŠ è½½ IndexTTS æ¨¡å‹
                logger.info(f"åŠ è½½é…ç½®: {cfg_path}")
                logger.info(f"æ¨¡å‹ç›®å½•: {settings.weights_dir}")
                logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

                # åˆå§‹åŒ– IndexTTS æ¨¡å‹
                use_cuda_kernel = self.device.startswith("cuda")
                kwargs = {
                    "cfg_path": str(cfg_path),
                    "model_dir": str(settings.weights_dir),
                    "use_fp16": use_cuda_kernel,
                    "use_cuda_kernel": use_cuda_kernel,
                    "use_deepspeed": False,
                }
                if "device" in inspect.signature(IndexTTS2).parameters:
                    kwargs["device"] = self.device
                
                logger.info(f"å¼€å§‹åˆå§‹åŒ– IndexTTS2ï¼Œå‚æ•°: {kwargs}")
                logger.info("è¿™å¯èƒ½éœ€è¦ 1-3 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…...")
                self.model = IndexTTS2(**kwargs)

                logger.info("âœ“ IndexTTS æ¨¡å‹åŠ è½½æˆåŠŸ")

            except ImportError as ie:
                logger.warning(f"æ— æ³•å¯¼å…¥ IndexTTS: {ie}")
                logger.warning("å›é€€åˆ° Mock æ¨¡å¼ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰")
                self.model = MockIndexTTS(self.device)
            except Exception as e:
                logger.error(f"IndexTTS åŠ è½½å¤±è´¥: {e}")
                logger.warning("å›é€€åˆ° Mock æ¨¡å¼ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰")
                self.model = MockIndexTTS(self.device)

            self.is_loaded = True
            logger.info("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")

            # å¯åŠ¨æ—¶é¢„çƒ­æ‰€æœ‰è§’è‰²çš„å‚è€ƒéŸ³é¢‘ç‰¹å¾
            self._warmup_all_voices()

        except Exception as e:
            logger.error(f"âœ— æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise RuntimeError(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    def _warmup_all_voices(self):
        """
        é¢„çƒ­æ‰€æœ‰è§’è‰²çš„å‚è€ƒéŸ³é¢‘ç‰¹å¾
        åœ¨å¯åŠ¨æ—¶è°ƒç”¨ï¼Œå°†æ‰€æœ‰è§’è‰²çš„ç‰¹å¾é¢„å…ˆè®¡ç®—å¹¶ç¼“å­˜åˆ°GPUæ˜¾å­˜
        """
        if isinstance(self.model, MockIndexTTS):
            logger.info("Mock æ¨¡å¼ï¼Œè·³è¿‡é¢„çƒ­")
            return

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒé¢„çƒ­
        if not hasattr(self.model, 'warmup_speaker'):
            logger.warning("æ¨¡å‹ä¸æ”¯æŒé¢„çƒ­åŠŸèƒ½ï¼Œè·³è¿‡")
            return

        logger.info("=" * 50)
        logger.info("ğŸ”¥ å¼€å§‹é¢„çƒ­è§’è‰²å‚è€ƒéŸ³é¢‘...")
        logger.info("=" * 50)

        warmup_count = 0
        failed_count = 0

        # 1. é¢„çƒ­ presets ç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³è‰²
        if settings.presets_dir.exists():
            # æ–°ç»“æ„: presets/{voice_id}/{emotion}.wav
            for voice_dir in settings.presets_dir.iterdir():
                if voice_dir.is_dir():
                    for wav_file in list(voice_dir.glob("*.wav")) + list(voice_dir.glob("*.WAV")):
                        try:
                            if self.model.warmup_speaker(str(wav_file)):
                                warmup_count += 1
                            else:
                                failed_count += 1
                        except Exception as e:
                            logger.warning(f"é¢„çƒ­å¤±è´¥ {wav_file}: {e}")
                            failed_count += 1

            # æ—§ç»“æ„: presets/{voice}.wav
            for wav_file in list(settings.presets_dir.glob("*.wav")) + list(settings.presets_dir.glob("*.WAV")):
                if wav_file.is_file():
                    try:
                        if self.model.warmup_speaker(str(wav_file)):
                            warmup_count += 1
                        else:
                            failed_count += 1
                    except Exception as e:
                        logger.warning(f"é¢„çƒ­å¤±è´¥ {wav_file}: {e}")
                        failed_count += 1

        # 2. é¢„çƒ­ char ç›®å½•ä¸‹çš„æ‰€æœ‰è§’è‰²éŸ³è‰²
        if settings.char_dir.exists():
            for char_dir in settings.char_dir.iterdir():
                if char_dir.is_dir():
                    for wav_file in list(char_dir.glob("*.wav")) + list(char_dir.glob("*.WAV")):
                        try:
                            if self.model.warmup_speaker(str(wav_file)):
                                warmup_count += 1
                            else:
                                failed_count += 1
                        except Exception as e:
                            logger.warning(f"é¢„çƒ­å¤±è´¥ {wav_file}: {e}")
                            failed_count += 1

        logger.info("=" * 50)
        logger.info(f"ğŸ”¥ é¢„çƒ­å®Œæˆ: æˆåŠŸ {warmup_count} ä¸ª, å¤±è´¥ {failed_count} ä¸ª")

        # æ‰“å°ç¼“å­˜çŠ¶æ€
        if hasattr(self.model, 'get_cache_info'):
            cache_info = self.model.get_cache_info()
            logger.info(f"ğŸ“Š ç¼“å­˜çŠ¶æ€: {cache_info['speaker_cache_size']} ä¸ªè¯´è¯äººå·²ç¼“å­˜")

        logger.info("=" * 50)

    def _get_reference_audio_path(self, voice_id: str, emotion: str = "default") -> Path:
        """
        è·å–å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ˆæ”¯æŒæ–°çš„å±‚çº§ç»“æ„å’Œè§’è‰²éŸ³è‰²ï¼‰
        æ–°ç»“æ„: presets/{voice_id}/{emotion}.wav
        è§’è‰²éŸ³è‰²: char/{char_id}/{voice_file}.wav
        """
        voice_id = voice_id.replace(".wav", "")
        emotion = emotion.replace(".wav", "")

        # æ£€æŸ¥æ˜¯å¦æ˜¯è§’è‰²éŸ³è‰²è·¯å¾„ (æ ¼å¼: char/{char_id}/{voice_name})
        if voice_id.startswith("char/"):
            parts = voice_id.split("/")
            if len(parts) >= 3:
                # char/{char_id}/{voice_name}
                char_id = parts[1]
                voice_name = parts[2]
                char_audio_path = settings.char_dir / char_id / f"{voice_name}.wav"
                if char_audio_path.exists():
                    logger.info(f"ä½¿ç”¨è§’è‰²éŸ³è‰²: {char_id}/{voice_name}")
                    return char_audio_path
                # å°è¯•å¤§å†™åç¼€
                char_audio_path_upper = settings.char_dir / char_id / f"{voice_name}.WAV"
                if char_audio_path_upper.exists():
                    logger.info(f"ä½¿ç”¨è§’è‰²éŸ³è‰²: {char_id}/{voice_name}")
                    return char_audio_path_upper
                raise FileNotFoundError(f"è§’è‰²éŸ³è‰²ä¸å­˜åœ¨: {char_audio_path}")

        voice_dir = settings.presets_dir / voice_id
        target_path = voice_dir / f"{emotion}.wav"

        if target_path.exists():
            logger.info(f"ä½¿ç”¨éŸ³è‰²: {voice_id}/{emotion}")
            return target_path

        # å°è¯•å¤§å†™åç¼€
        target_path_upper = voice_dir / f"{emotion}.WAV"
        if target_path_upper.exists():
            logger.info(f"ä½¿ç”¨éŸ³è‰²: {voice_id}/{emotion}")
            return target_path_upper

        default_path = voice_dir / "default.wav"
        if default_path.exists():
            logger.warning(f"æƒ…æ„Ÿ {emotion} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ {voice_id}/default")
            return default_path

        # å°è¯•å¤§å†™åç¼€
        default_path_upper = voice_dir / "default.WAV"
        if default_path_upper.exists():
            logger.warning(f"æƒ…æ„Ÿ {emotion} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ {voice_id}/default")
            return default_path_upper

        old_structure_path = settings.presets_dir / f"{voice_id}.wav"
        if old_structure_path.exists():
            logger.warning(f"ä½¿ç”¨æ—§ç»“æ„éŸ³è‰²: {voice_id}.wavï¼ˆå»ºè®®è¿ç§»åˆ°æ–°ç»“æ„ï¼‰")
            return old_structure_path

        # å°è¯•å¤§å†™åç¼€
        old_structure_path_upper = settings.presets_dir / f"{voice_id}.WAV"
        if old_structure_path_upper.exists():
            logger.warning(f"ä½¿ç”¨æ—§ç»“æ„éŸ³è‰²: {voice_id}.WAVï¼ˆå»ºè®®è¿ç§»åˆ°æ–°ç»“æ„ï¼‰")
            return old_structure_path_upper

        raise FileNotFoundError(
            f"éŸ³è‰² {voice_id} ä¸å­˜åœ¨ã€‚è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€å­˜åœ¨ï¼š\n"
            f"  - {target_path}\n"
            f"  - {default_path}\n"
            f"  - {old_structure_path}"
        )

    async def generate(
        self,
        text: str,
        voice_id: str = "default",
        emotion: str = "default",
        speed: float = 1.0,
        temperature: float = 1.0,
        top_p: float = 0.8,
        top_k: int = 20,
        repetition_penalty: float = 1.0,
        request_id: Optional[str] = None
    ) -> np.ndarray:
        """ç”Ÿæˆè¯­éŸ³ï¼ˆå¼‚æ­¥ï¼Œå¸¦æ˜¾å­˜é”ä¿æŠ¤å’Œé˜Ÿåˆ—ç®¡ç†ï¼‰"""
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_model()")

        # ç”Ÿæˆè¯·æ±‚ID
        if request_id is None:
            request_id = str(uuid.uuid4())

        # æ·»åŠ åˆ°é˜Ÿåˆ—
        success, position = await tts_queue.add(request_id)
        if not success:
            raise RuntimeError(f"é˜Ÿåˆ—å·²æ»¡ï¼ˆæœ€å¤§ {MAX_QUEUE_SIZE}ï¼‰ï¼Œè¯·ç¨åé‡è¯•")

        logger.info(f"è¯·æ±‚ {request_id[:8]}... åŠ å…¥é˜Ÿåˆ—ï¼Œä½ç½®: {position}")

        try:
            if emotion == "auto":
                from app.services.sentiment import sentiment_analyzer
                emotion = await sentiment_analyzer.analyze(text)
                logger.info(f"æ™ºèƒ½æƒ…æ„Ÿåˆ†æç»“æœ: {emotion}")

            ref_audio_path = self._get_reference_audio_path(voice_id, emotion)

            # è®¾ç½®ä¸ºæ­£åœ¨å¤„ç†
            await tts_queue.set_processing(request_id)

            async with self.inference_lock:
                logger.info(
                    f"å¼€å§‹æ¨ç†: text_len={len(text)}, voice={voice_id}, emotion={emotion}, "
                    f"speed={speed}, temp={temperature}, top_p={top_p}, top_k={top_k}, rep_penalty={repetition_penalty}"
                )
                try:
                    loop = asyncio.get_event_loop()
                    audio_data = await loop.run_in_executor(
                        None,
                        self._sync_generate,
                        text,
                        str(ref_audio_path),
                        speed,
                        temperature,
                        top_p,
                        top_k,
                        repetition_penalty
                    )
                    logger.info(f"âœ“ æ¨ç†å®Œæˆï¼ŒéŸ³é¢‘é•¿åº¦: {len(audio_data)} samples")
                    return audio_data
                except Exception as e:
                    logger.error(f"âœ— æ¨ç†å¤±è´¥: {e}")
                    raise RuntimeError(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        finally:
            # ä»é˜Ÿåˆ—ç§»é™¤
            await tts_queue.remove(request_id)

    def _sync_generate(
        self, 
        text: str, 
        ref_audio_path: str, 
        speed: float,
        temperature: float,
        top_p: float,
        top_k: int,
        repetition_penalty: float
    ) -> np.ndarray:
        """åŒæ­¥æ¨ç†å‡½æ•°ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        with torch.no_grad():
            if isinstance(self.model, MockIndexTTS):
                return self.model.synthesize(text, ref_audio_path, speed)

            try:
                result = self.model.infer(
                    spk_audio_prompt=ref_audio_path,
                    text=text,
                    output_path=None,
                    top_p=top_p,
                    top_k=top_k,
                    temperature=temperature,
                    repetition_penalty=repetition_penalty
                )

                sample_rate = settings.sample_rate
                audio_data = result
                if isinstance(result, tuple) and len(result) == 2:
                    sample_rate, audio_data = result
                elif isinstance(result, str):
                    audio_data, sample_rate = sf.read(result)
                elif result is None:
                    raise RuntimeError("æ¨¡å‹æœªè¿”å›éŸ³é¢‘æ•°æ®")

                if isinstance(audio_data, torch.Tensor):
                    audio_data = audio_data.cpu().numpy()

                if isinstance(audio_data, np.ndarray):
                    if audio_data.dtype in (np.int16, np.int32):
                        max_val = np.iinfo(audio_data.dtype).max
                        audio_data = audio_data.astype(np.float32) / max_val
                    else:
                        audio_data = audio_data.astype(np.float32, copy=False)

                if len(audio_data.shape) > 1:
                    if audio_data.shape[0] == 1:
                        audio_data = audio_data.squeeze(0)
                    elif audio_data.shape[1] == 1:
                        audio_data = audio_data.squeeze(1)
                    else:
                        audio_data = audio_data.mean(axis=1)

                if speed != 1.0:
                    audio_data = self._adjust_speed(audio_data, sample_rate, speed)

                if sample_rate != settings.sample_rate:
                    audio_data = self._resample_audio(audio_data, orig_sr=sample_rate, target_sr=settings.sample_rate)

                return audio_data.astype(np.float32, copy=False)

            except Exception as e:
                logger.error(f"IndexTTS æ¨ç†å¤±è´¥: {e}")
                raise

    def _adjust_speed(self, audio: np.ndarray, sample_rate: int, speed: float) -> np.ndarray:
        """è°ƒæ•´éŸ³é¢‘é€Ÿåº¦"""
        try:
            import librosa
            return librosa.effects.time_stretch(audio, rate=speed)
        except ImportError:
            logger.warning("librosa æœªå®‰è£…ï¼Œæ— æ³•è°ƒæ•´è¯­é€Ÿ")
            return audio
        except Exception as e:
            logger.warning(f"è¯­é€Ÿè°ƒæ•´å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹éŸ³é¢‘")
            return audio

    def _resample_audio(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """é‡é‡‡æ ·éŸ³é¢‘"""
        try:
            import librosa
            return librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)
        except ImportError:
            logger.warning("librosa æœªå®‰è£…ï¼Œæ— æ³•é‡é‡‡æ ·")
            return audio
        except Exception as e:
            logger.warning(f"é‡é‡‡æ ·å¤±è´¥: {e}ï¼Œè¿”å›åŸå§‹éŸ³é¢‘")
            return audio


class MockIndexTTS:
    """Mock æ¨¡å‹ï¼ˆç”¨äºæµ‹è¯•ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€æ›¿æ¢ï¼‰"""

    def __init__(self, device: str):
        self.device = device
        logger.warning("âš ï¸  ä½¿ç”¨ Mock æ¨¡å‹ï¼Œè¯·æ›¿æ¢ä¸ºçœŸå®çš„ IndexTTS å®ç°")

    def synthesize(self, text: str, ref_audio: str, speed: float) -> np.ndarray:
        import time
        time.sleep(0.5)
        duration = len(text) * 0.1
        samples = int(settings.sample_rate * duration)
        return np.zeros(samples, dtype=np.float32)


tts_engine = TTSModelEngine()
