# 演示脚本

## 准备工作

### 1. 启动服务
```bash
# 在项目根目录
./start_all.sh
```

等待服务启动完成，看到：
- ✅ 后端运行在 http://localhost:8080
- ✅ 前端运行在 http://localhost:3000

### 2. 打开浏览器
访问：http://localhost:3000

## 演示流程

### 第一步：配置设置

1. 首次打开会自动弹出设置面板
2. 填写 LLM 配置：
   - Base URL: `https://api.openai.com/v1`
   - API Key: `sk-xxxxx`（你的真实 Key）
   - Model: `gpt-4`
   
3. 点击"获取列表"按钮（可选）
   - 展示如何自动拉取模型列表
   
4. 填写 TTS 配置：
   - TTS API URL: `http://localhost:8080/v1/audio/speech`
   - Character Voice: `girl_01`
   
5. 点击"保存"

### 第二步：基础对话

**输入**：
```
你好，请介绍一下你自己
```

**观察**：
- 消息立即显示在聊天界面
- AI 开始流式回复（打字机效果）
- 如果回复中有引号，会被高亮显示

### 第三步：语音合成演示

**输入**：
```
请给我讲一个小红帽的故事，用对话的形式
```

**观察**：
1. AI 开始回复故事
2. 当出现第一个完整的引号时：
   - 文本被高亮显示（蓝色背景）
   - 自动开始语音合成
   - 音频开始播放
3. 后续的对话依次播放（不会重叠）
4. 消息旁出现喇叭图标

### 第四步：重播功能

1. 点击消息旁的喇叭图标
2. 该消息中的所有语音会重新播放

### 第五步：多轮对话

**输入**：
```
继续讲，小红帽遇到了大灰狼
```

**观察**：
- 上下文保持
- 新的对话继续转为语音
- 音频队列自动管理

### 第六步：设置修改

1. 点击右上角的设置图标
2. 修改 Voice 为 `boy_01`
3. 保存
4. 发送新消息，观察声音变化

### 第七步：清空对话

1. 点击右上角的垃圾桶图标
2. 确认清空
3. 所有消息被清除
4. 音频播放停止

## 测试用例

### 用例 1: 简单对话
```
用户: 今天天气怎么样？
AI: 我说："今天天气很好。"
```
✅ 应该播放："今天天气很好。"

### 用例 2: 多句对话
```
用户: 请用对话形式讲个笑话
AI: 小明问："你知道什么动物最爱问为什么吗？"
    小红回答："不知道，是什么？"
    小明笑着说："是猪啊，因为猪总是问'为什么'！"
```
✅ 应该依次播放三句话

### 用例 3: 中英文混合
```
用户: 用中英文对话
AI: 老师说："Today we learn English."
    学生回答："好的，老师。"
```
✅ 应该播放两句话

### 用例 4: 无引号内容
```
用户: 介绍一下 Python
AI: Python 是一种高级编程语言...（无引号）
```
✅ 不应该播放任何语音

### 用例 5: 长对话
```
用户: 讲一个长故事
AI: （包含 10+ 句对话）
```
✅ 所有对话应该按顺序播放，不重叠

## 性能测试

### 测试 1: 快速连续发送
1. 快速发送 3 条消息
2. 观察是否正常处理
3. 检查音频队列是否正常

### 测试 2: 长文本
1. 发送要求生成长文本的消息
2. 观察流式响应是否流畅
3. 检查内存使用

### 测试 3: 网络中断
1. 断开网络
2. 发送消息
3. 观察错误提示
4. 恢复网络后重试

## 边界情况

### 情况 1: 空消息
- 输入框为空时，发送按钮应该禁用

### 情况 2: 正在发送时
- 发送中时，输入框和按钮应该禁用
- 显示"发送中..."

### 情况 3: API 错误
- LLM API 错误时，显示错误消息
- TTS API 错误时，在控制台显示错误

### 情况 4: 配置缺失
- 未配置时，点击发送应该打开设置面板

## 浏览器兼容性测试

测试以下浏览器：
- ✅ Chrome/Edge (推荐)
- ✅ Firefox
- ✅ Safari
- ⚠️ 移动浏览器（响应式）

## 演示技巧

### 1. 准备好测试数据
- 提前准备好 API Key
- 确保 TTS 服务正常运行
- 准备好演示用的提示词

### 2. 突出核心功能
- 强调实时提取（边生成边播放）
- 展示音频队列（不重叠）
- 演示高亮显示

### 3. 处理意外情况
- 如果 API 慢，解释是网络原因
- 如果语音不清晰，可以切换 voice
- 如果出错，展示错误处理机制

### 4. 互动环节
- 让观众提供测试用例
- 现场修改配置
- 展示代码结构

## 演示后的 Q&A

### 常见问题

**Q: 支持哪些 LLM？**
A: 所有兼容 OpenAI API 的服务，包括 OpenAI、Azure OpenAI、各种中转服务等。

**Q: 可以自定义提取规则吗？**
A: 可以，修改 `utils/audioQueue.ts` 中的正则表达式即可。

**Q: 支持其他 TTS 服务吗？**
A: 可以，修改 `AudioQueueManager.synthesizeSpeech()` 方法适配不同的 API。

**Q: 如何部署到生产环境？**
A: 参考 `QUICK_START.md` 中的部署章节，支持 Vercel、Docker 等多种方式。

**Q: 性能如何？**
A: 前端非常轻量，主要性能取决于 LLM 和 TTS API 的响应速度。

**Q: 支持移动端吗？**
A: 支持，使用响应式设计，可以在移动浏览器中使用。

## 演示检查清单

演示前确认：
- [ ] 后端服务正常运行
- [ ] 前端服务正常运行
- [ ] API Key 有效
- [ ] TTS 服务可访问
- [ ] 浏览器音频权限已授予
- [ ] 网络连接稳定
- [ ] 准备好演示用例
- [ ] 了解代码结构
- [ ] 准备好回答常见问题

演示后：
- [ ] 收集反馈
- [ ] 记录问题
- [ ] 优化改进
- [ ] 更新文档
