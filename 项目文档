这是一份为你精心准备的**《IndexTTS 2.0 语音合成微服务 - 开发需求文档 (PRD)》**。

这份文档的设计逻辑是：**高度模块化、上下文清晰、约束明确**。你可以直接将这份文档复制发送给 AI 编程助手（如 ChatGPT, Claude, Cursor, 或者 Windsurf），它就能立刻理解并生成高质量、可运行的代码。

---

# 项目代号：VoiceNexus (IndexTTS API Service)

## 1. 项目概述

本项目旨在基于 B站开源的 **IndexTTS 2.0** 模型，构建一个高性能、易部署的**语音合成 API 微服务**。该服务将部署在 Ubuntu 服务器上，通过 Docker 容器化运行，并提供标准 HTTP 接口供下游应用（如聊天软件、Web 前端）调用。

**核心特性：**

* **基于预设音色：** 通过读取服务器本地的 `.wav` 参考音频文件来实现不同的角色音色（无需训练）。
* **显存保护：** 实现请求排队机制（Queueing），防止多并发导致 8GB 显存溢出。
* **流式输出：** 支持音频流式返回，降低用户等待延迟。
* **简单运维：** 使用 Docker Compose 一键部署，配合 Cloudflare Tunnel 暴露服务。

---

## 2. 技术栈 (Tech Stack)

* **OS:** Ubuntu 22.04 LTS
* **Language:** Python 3.10+
* **Framework:** FastAPI (Async)
* **Model Engine:** PyTorch (CUDA 11.8/12.1), IndexTTS 2.0 SDK
* **Audio Processing:** FFmpeg, torchaudio
* **Containerization:** Docker, Docker Compose (NVIDIA Container Toolkit)
* **Architecture:** Monolithic Microservice (单体微服务)

---

## 3. 系统架构与目录结构

请 AI 严格按照以下目录结构生成代码：

```text
/project_root
├── app/
│   ├── __init__.py
│   ├── main.py              # FastAPI 入口，定义 API 路由
│   ├── core/
│   │   ├── config.py        # 环境变量配置 (Pydantic)
│   │   └── inference.py     # 核心推理类 (IndexTTS Wrapper)，封装模型加载与推理
│   ├── models/
│   │   └── schemas.py       # Pydantic 数据模型 (Request/Response)
│   └── utils/
│       └── audio.py         # 音频处理工具 (格式转换)
├── weights/                 # [挂载] 存放模型权重文件 (.pth, .bin)
├── presets/                 # [挂载] 存放参考音频 (.wav)，即“音色库”
├── logs/                    # [挂载] 运行日志
├── requirements.txt         # Python 依赖
├── Dockerfile               # 构建镜像
├── docker-compose.yml       # 编排文件
└── README.md

```

---

## 4. 详细功能需求 (Functional Requirements)

### 4.1. 核心推理模块 (`app/core/inference.py`)

* **类名：** `TTSModelEngine`
* **功能：**
* **单例加载：** 在应用启动时加载模型到 CUDA，避免每次请求重复加载。
* **推理函数：** 接收 `text` (文本), `voice_id` (音色文件名), `speed` (语速)。
* **音色匹配逻辑：** 根据 `voice_id` 在 `/app/presets/` 目录下查找对应的 `.wav` 文件。如果文件不存在，回退到默认音频。
* **显存锁 (Critical)：** 使用 `asyncio.Lock()`，确保同一时刻只有一个请求在调用 GPU 推理，避免 OOM (Out Of Memory)。



### 4.2. API 接口定义 (`app/main.py`)

**接口 A：获取可用音色列表**

* **Method:** `GET /v1/voices`
* **逻辑：** 扫描 `/app/presets/` 目录下的所有 `.wav` 文件。
* **Response:**
```json
{
  "voices": [
    {"id": "girl_01", "filename": "girl_01.wav", "name": "girl_01"},
    {"id": "uncle_li", "filename": "uncle_li.wav", "name": "uncle_li"}
  ]
}

```



**接口 B：语音合成**

* **Method:** `POST /v1/audio/speech`
* **Request Body:**
```json
{
  "model": "indextts-2.0",
  "input": "你好，这是测试文本。",
  "voice": "girl_01",  // 对应 presets 里的文件名
  "response_format": "wav", // 支持 wav, mp3
  "speed": 1.0
}

```


* **Response:** 返回音频文件的二进制流 (`StreamingResponse`), `media_type="audio/wav"`.

**接口 C：上传新音色 (管理端用)**

* **Method:** `POST /v1/voices/upload`
* **Request:** `multipart/form-data` (上传一个 .wav 文件)。
* **逻辑：** 将文件保存到 `/app/presets/`，并验证是否为有效音频。

### 4.3. Docker 部署配置

* **Base Image:** 使用 `pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime` (或兼容版本)。
* **System Deps:** 安装 `ffmpeg`, `git`, `libsndfile1`.
* **Volume Mapping:**
* `./weights:/app/weights`
* `./presets:/app/presets`



---

## 5. 逐步开发指令 (Prompt Strategy)

**为了获得最佳效果，请分步骤向 AI 发送以下指令（不要一次性发全部，容易乱）：**

### 第一轮指令：搭建项目骨架

> "我正在开发一个基于 IndexTTS 2.0 的语音合成 API。请根据以下目录结构，为我生成 `app/models/schemas.py`（定义请求参数）和 `app/core/config.py`（配置类）。同时，请生成 `requirements.txt`，包含 fastapi, uvicorn, python-multipart, torch, torchaudio, numpy 等必要依赖。"

### 第二轮指令：编写核心推理类

> "现在我们需要编写最核心的推理逻辑 `app/core/inference.py`。
> 假设 IndexTTS 的官方推理代码已经准备好（你可以先用伪代码 `MockIndexTTS` 代替具体模型调用），请帮我封装一个 `TTSModelEngine` 类。
> **关键要求：**
> 1. 实现 `load_model` 方法。
> 2. 实现 `generate` 方法，接受文本和参考音频路径。
> 3. 必须包含一个 `asyncio.Lock`，确保 generate 方法是线程安全的，同一时间只能处理一个请求。
> 4. 实现逻辑：如果传入的 `voice_id` 对应的 wav 文件不存在，自动降级使用 `default.wav`。"
> 
> 

### 第三轮指令：编写 API 路由

> "请编写 `app/main.py`。
> 1. 使用 FastAPI 的 `lifespan` 机制在启动时初始化 `TTSModelEngine`。
> 2. 实现 `GET /v1/voices` 接口，扫描本地文件夹返回文件列表。
> 3. 实现 `POST /v1/audio/speech` 接口，调用 Engine 生成音频，并使用 `StreamingResponse` 返回流式数据。
> 4. 实现 `POST /v1/voices/upload` 接口，允许用户上传 wav 文件到 preset 目录。"
> 
> 

### 第四轮指令：Docker 化

> "最后，请为这个项目编写 `Dockerfile` 和 `docker-compose.yml`。
> 1. Dockerfile 基于 PyTorch 官方 CUDA 镜像，确保安装了 ffmpeg。
> 2. docker-compose 需要挂载 `./weights` 和 `./presets` 目录，并开启 GPU 支持（deploy resources reserve gpu）。"
> 
> 

---

## 6. 特别提示（你需要注意的）

1. **关于 IndexTTS 的真实源码：**
AI 可能无法凭空写出 IndexTTS 2.0 **内部具体**的张量处理代码（因为它太新了）。
* **解决办法：** 你需要先去 IndexTTS 的 GitHub 仓库下载官方的 `inference.py` 或 `demo.py`。
* **给 AI 的指令：** 当你做第二轮（核心推理类）时，把官方的 `inference.py` 内容粘贴给 AI，对它说：“这是官方的推理 demo，请把这个逻辑集成到我刚才让你写的 `TTSModelEngine` 类里。”


2. **关于 Cloudflare：**
在项目跑通后，你只需要在宿主机运行：
`cloudflared tunnel --url localhost:5050`
不需要在代码里写任何 Cloudflare 相关的逻辑。

你需要做的就是拿着这份文档，按照“逐步开发指令”去“喂”你的 AI 助手。祝开发顺利！